### Spatial Convolutional Neural Network 
This folder contains codes to generate feature vectors of the UCF-101 database. The generated features are used for our network for temporal design: baseline CNN, CNN+RNN, and TCNN

All the codes are implemented by Min-Hung Chen from scratch.

=============================================================================
## Requirement
There are some libraries you need to install before running my codes.
# download data:
wget http://crcv.ucf.edu/data/UCF11_updated_mpg.rar

# if you dont have unrar (or use sudo apt-get):
wget http://www.rarlab.com/rar/rarlinux-3.6.0.tar.gz
tar -zxvf rarlinux-*.tar.gz
./rar/unrar x UCF11_updated_mpg.rar (unRAR the data)

# get ffmpeg library:
sudo apt-get install ffmpeg

# get video libraries for lua:
luarocks install ffmpeg

# Common Problems
1. ffmpeg installation problems for Ubuntu 14.04:
sudo add-apt-repository ppa:mc3man/trusty-media
sudo apt-get update
sudo apt-get dist-upgrade
sudo apt-get install ffmpeg

2. run 32-bit unrar in a 64-bit system
	* For Ubuntu 13.10 and above
sudo dpkg --add-architecture i386
sudo apt-get update
sudo apt-get install libncurses5:i386 libstdc++6:i386 zlib1g:i386

	* For earlier version
apt-get install ia32-libs

=============================================================================
## File List & Implementation details & Usage:
If you don't want to try all the codes, you can just try the first one, which is used to generate our final Res-101 features.

-----------------------------------------------------------------------------
# run_UCF101_final_ResNet.lua:
similar as "run_UCF101_final.lua", but using the model "ResNet-101"
extract the feature before the full-connected layer
generate the name list as well

command: th run_UCF101_final_ResNet.lua 

notes: **THIS is the only code to generate our final features !!!**
1. You need to downoload the dataset and modify the path in the code
2. parameters: 
	feature dimension = 2048
	class#, frame#: same as "run_UCF101_final.lua"
3. There are four kinds of outputs (name, path, featMats & labels) & three numbers
	name, path:	same as "run_UCF101_final_nameList.lua"
	numVideo, featMats, labels, numClass, c_finished: same as "run_UCF101_final.lua"
4. running time: around 3.7 times of "run_UCF101_final.lua"
5. need "transforms.lua" to pre-process images	

-----------------------------------------------------------------------------
## run_UCF101_final_caffe.lua:
similar as "run_UCF101_final.lua", but using the caffe model "VGG_M"
extract the fc-6 feature (follow the LRCN paper)
generate the name list as well

command: th run_UCF101_final_caffe.lua 

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: 
	feature dimension = 4096
	class#, frame#: same as "run_UCF101_final.lua"
3. There are four kinds of outputs (name, path, featMats & labels) & three numbers
	name, path:	same as "run_UCF101_final_nameList.lua"
	numVideo, featMats, labels, numClass, c_finished: same as "run_UCF101_final.lua"
4. running time: around 5 times of "run_UCF101_final.lua"
	
-----------------------------------------------------------------------------
## run_UCF101_final_nameList.lua:
Generate the name list corresponding to the features generated by "run_UCF101_final.lua"

command: th run_UCF101_final_nameList.lua 

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: same as "run_UCF101_final.lua"
3. There are two kinds of outputs (name & path) & three numbers
	name: 		video name
	path:		local video path (under "UCF-101/")
	numVideo, numClass, c_finished:	same as "run_UCF101_final.lua"

=============================================================================
## classify_video_debug.lua:
Load one image --> predict the label or generate the features for that image

command: th classify_video_debug.lua

there are 3 main parameters:
modelLang:	choose 'torch' or 'caffe'
typeCode:	based on different sample codes ==> 1. original; 2. ResNet
Ft:		different modes ==> true: extract features; false: predict labels

notes:
1. model choices: nin_nobn_final.t7, resnet-101.t7, VGG caffe model

-----------------------------------------------------------------------------
## run_UCF101_final.lua:
Load most of the videos in UCF-101 (use CUDA for default)
no need to specify the video number ==> use all the videos above the user-defined minimal frame#
follow the original author's split sets to generate 3 training/testing sets

command: th run_UCF101_final.lua 

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: same as "run_UCF101_2.lua"
3. There are two kinds of outputs (featMats & labels) & three numbers
	numVideo:	depend on training or testing sets (total: 13265)	
	featMats, labels, numClass, c_finished:	same as "run_UCF101_2.lua"

-----------------------------------------------------------------------------
## run_UCF101_2.lua:
Load most of the videos in UCF-101 (use CUDA for default)
no need to specify the video number ==> use all the videos above the user-defined minimal frame#

command: qlua (-lenv) run_UCF101_2.lua ("-lenv" for printing tables)

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: 
	class# = 101
	feature dimension = 1024
	frame# = 50 (I chose from one short video)
3. There are two kinds of outputs (featMats & labels) & three numbers
	featMats: 	total video# x feature dimension x frame#
	labels:		total video# x 1
	numVideo:	13308
	numClass:	101
	c_finished:	103 (no need to care...just a flag^^)
4. need "classify_video.lua" or "gen_feature.lua" to do classification or feature generation.	

-----------------------------------------------------------------------------
## run_UCF101.lua:
Load most of the videos in UCF-101 (recommend to use CUDA)

command: qlua run_UCF101.lua -p cuda

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: 
	class# = 101
	video# in each group = 90 (because there are at least 100 videos)
	total video# = 101*90 = 9090
	feature dimension = 1024
	frame# = 57 (I chose from one short video)
3. There are two kinds of outputs: featMats & labels
	featMats: 	total video# x feature dimension x frame#
	labels:		total video# x 1
4. need "classify_video.lua" or "gen_feature.lua" to do classification or feature generation.

-----------------------------------------------------------------------------
## run_UCF11.lua:
Load all the videos in UCF-11 

command: qlua run_UCF11.lua

notes:
1. You need to put all the videos in the folder '../Dataset/.....'
2. parameters: 
	class# = 11
	group# in each class = 25
	video# in each group = 4 (because there are at least 4 videos)
	total video# = 11*25*4 = 1100
	feature dimension = 1024
	frame# = 57 (I chose the shortest video)
3. There are two kinds of outputs: featMats & labels
	featMats: 	total video# x feature dimension x frame#
	labels:		total video# x 1
4. need "classify_video.lua" or "gen_feature.lua" to do classification or feature generation.

-----------------------------------------------------------------------------
## run.lua: 
Load one video and do the following two things: 
1. generate the feature matrix (need 'gen_feature.lua')
2. make prediction frame-by-frame (need 'classify_video')
You can choose to turn the function on or off by yourself

command: qlua run.lua (-v your_video)

It will do the following steps:
1. load the video from '../Dataset/.....' (You need to download the UCF-11 first)
2. load the pre-trained model ("NIN" network) & the ImageNet labels
3. process the video

note: need "classify_video.lua" or "gen_feature.lua" to do classification or feature generation.

=============================================================================
Other notes:
1. After running these codes, a new empty folder "out_frames" will be generated. You can ignore it. That's only for debugging.
2. The images in the folder "images" are only for debugging. They won't be used in the final experiment.

=============================================================================
#Contact: Min-Hung Chen
E-mail: cmhungsteve@gatech.edu
Last updated: 05/02/2016
