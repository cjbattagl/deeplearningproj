## run_UCF101_final_ResNet.lua:
similar as "run_UCF101_final.lua", but using the model "ResNet-101"
extract the feature before the full-connected layer
generate the name list as well

command: th run_UCF101_final_ResNet.lua 

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: 
	feature dimension = 2048
	class#, frame#: same as "run_UCF101_final.lua"
3. There are four kinds of outputs (name, path, featMats & labels) & three numbers
	name, path:	same as "run_UCF101_final_nameList.lua"
	numVideo, featMats, labels, numClass, c_finished: same as "run_UCF101_final.lua"
4. running time: around 3.7 times of "run_UCF101_final.lua"
5. need "transforms.lua" to pre-process images	
=============================================================================
## run_UCF101_final_caffe.lua:
similar as "run_UCF101_final.lua", but using the caffe model "VGG_M"
extract the fc-6 feature (follow the LRCN paper)
generate the name list as well

command: th run_UCF101_final_caffe.lua 

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: 
	feature dimension = 4096
	class#, frame#: same as "run_UCF101_final.lua"
3. There are four kinds of outputs (name, path, featMats & labels) & three numbers
	name, path:	same as "run_UCF101_final_nameList.lua"
	numVideo, featMats, labels, numClass, c_finished: same as "run_UCF101_final.lua"
4. running time: around 5 times of "run_UCF101_final.lua"
	
=============================================================================
## run_UCF101_final_nameList.lua:
Generate the name list corresponding to the features generated by "run_UCF101_final.lua"

command: th run_UCF101_final_nameList.lua 

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: same as "run_UCF101_final.lua"
3. There are two kinds of outputs (name & path) & three numbers
	name: 		video name
	path:		local video path (under "UCF-101/")
	numVideo, numClass, c_finished:	same as "run_UCF101_final.lua"

=============================================================================
## classify_video_debug.lua:
Load one image --> predict the label or generate the features for that image

command: th classify_video_debug.lua

there are 3 main parameters:
modelLang:	choose 'torch' or 'caffe'
typeCode:	based on different sample codes ==> 1. original; 2. ResNet
Ft:		different modes ==> true: extract features; false: predict labels

notes:
1. model choices: nin_nobn_final.t7, resnet-101.t7, VGG caffe model

=============================================================================
## run_UCF101_final.lua:
Load most of the videos in UCF-101 (use CUDA for default)
no need to specify the video number ==> use all the videos above the user-defined minimal frame#
follow the original author's split sets to generate 3 training/testing sets

command: th run_UCF101_final.lua 

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: same as "run_UCF101_2.lua"
3. There are two kinds of outputs (featMats & labels) & three numbers
	numVideo:	depend on training or testing sets (total: 13265)	
	featMats, labels, numClass, c_finished:	same as "run_UCF101_2.lua"

=============================================================================
## run_UCF101_2.lua:
Load most of the videos in UCF-101 (use CUDA for default)
no need to specify the video number ==> use all the videos above the user-defined minimal frame#

command: qlua (-lenv) run_UCF101_2.lua ("-lenv" for printing tables)

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: 
	class# = 101
	feature dimension = 1024
	frame# = 50 (I chose from one short video)
3. There are two kinds of outputs (featMats & labels) & three numbers
	featMats: 	total video# x feature dimension x frame#
	labels:		total video# x 1
	numVideo:	13308
	numClass:	101
	c_finished:	103 (no need to care...just a flag^^)

=============================================================================
## run_UCF101.lua:
Load most of the videos in UCF-101 (recommend to use CUDA)

command: qlua run_UCF101.lua -p cuda

notes:
1. You need to downoload the dataset and modify the path in the code
2. parameters: 
	class# = 101
	video# in each group = 90 (because there are at least 100 videos)
	total video# = 101*90 = 9090
	feature dimension = 1024
	frame# = 57 (I chose from one short video)
3. There are two kinds of outputs: featMats & labels
	featMats: 	total video# x feature dimension x frame#
	labels:		total video# x 1

=============================================================================
## run_UCF11.lua:
Load all the videos in UCF-11  

command: qlua run_UCF11.lua

notes:
1. You need to put all the videos in the folder '../Dataset/.....'
2. parameters: 
	class# = 11
	group# in each class = 25
	video# in each group = 4 (because there are at least 4 videos)
	total video# = 11*25*4 = 1100
	feature dimension = 1024
	frame# = 57 (I chose the shortest video)
3. There are two kinds of outputs: featMats & labels
	featMats: 	total video# x feature dimension x frame#
	labels:		total video# x 1

=============================================================================
## run.lua: 
Load one video and do the following two things: 
1. generate the feature matrix (need 'gen_feature.lua')
2. make prediction frame-by-frame (need 'classify_video')
You can choose to turn the function on or off by yourself

command: qlua run.lua (-v your_video)

It will do the following steps:
1. load the video from '../Dataset/.....' (You need to download the UCF-11 first)
2. load the pre-trained model ("NIN" network) & the ImageNet labels
3. process the video

=============================================================================
After running these codes, a new empty folder "out_frames" will be generated. You can ignore it. That's only for debugging.
